# -*- coding: utf-8 -*-
"""HeardU

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tTyLRj7pAKgt4uC3w7Jairti0FXKZkF1
"""

!pip install numpy==1.24.4

# ğŸŒŸ Whisper Context-aware Fine-tuning Colab Template (Validation í¬í•¨)

# 0. Google Drive ë§ˆìš´íŠ¸
from google.colab import drive
drive.mount('/content/drive')

# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
!pip install torch==2.0.1 torchvision==0.15.2 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118
!pip install git+https://github.com/openai/whisper.git
!pip install datasets librosa accelerate transformers scikit-learn

# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
import torch
import whisper
import torchaudio
import json
from torch.utils.data import Dataset, DataLoader
from transformers import get_scheduler
from tqdm import tqdm
import os
from sklearn.model_selection import train_test_split

# 3. ë°ì´í„°ì„¸íŠ¸ í´ë˜ìŠ¤ ì •ì˜
class ContextDataset(Dataset):
    def __init__(self, file_list):
        self.data = file_list

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        audio_path, label, context = self.data[idx]
        audio, sr = torchaudio.load(audio_path)
        if sr != 16000:
            resampler = torchaudio.transforms.Resample(sr, 16000)
            audio = resampler(audio)
        audio = audio.squeeze()

        full_label = context + " " + label

        return audio, full_label

# 4. ëª¨ë¸ ë¡œë“œ
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisper.load_model("tiny").to(device)

# 5. Optimizer, Loss ì •ì˜
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)
loss_fn = torch.nn.CrossEntropyLoss()

# 6. ë°ì´í„° ì¤€ë¹„ ë° ë¶„í• 
'''
#íŒŒì¼ ê°œìˆ˜ 190ê°œ
# wav íŒŒì¼ í´ë” ê²½ë¡œ
wav_folder = "/content/drive/MyDrive/á„‹á…µá†«á„Œá…µá„‹á…³á†¼á„á…µá†·á„‘á…³á†¯/content/wav_files/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª07_F_1522434093_60_á„€á…§á†¼á„‰á…¡á†¼_á„‰á…µá†¯á„‚á…¢"
# json íŒŒì¼ í´ë” ê²½ë¡œ
json_folder = "/content/drive/MyDrive/á„‹á…µá†«á„Œá…µá„‹á…³á†¼á„á…µá†·á„‘á…³á†¯/content/json_files/á„‚á…©á„‹á…µá†«á„‚á…¡á†·á„‹á…§_á„‚á…©á„‹á…µá†«á„ƒá…¢á„’á…ª07_F_1522434093_60_á„€á…§á†¼á„‰á…¡á†¼_á„‰á…µá†¯á„‚á…¢"
'''
# íŒŒì¼ê°œìˆ˜ 480ê°œ
# wav íŒŒì¼ í´ë” ê²½ë¡œ
wav_folder = "/content/drive/MyDrive/á„‹á…µá†«á„Œá…µá„‹á…³á†¼á„á…µá†·á„‘á…³á†¯/content/wav_files/á„á…®á†¼á„á…¥á†¼"
# json íŒŒì¼ í´ë” ê²½ë¡œ
json_folder = "/content/drive/MyDrive/á„‹á…µá†«á„Œá…µá„‹á…³á†¼á„á…µá†·á„‘á…³á†¯/content/json_files/á„á…®á†¼á„á…¥á†¼"


file_list = []
i = 0
for filename in os.listdir(wav_folder):
    i += 1
    if filename.endswith(".wav"):
        base_name = filename[:-4]
        audio_path = os.path.join(wav_folder, filename)
        json_path = os.path.join(json_folder, base_name + ".json")

         # json íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
        if not os.path.exists(json_path):
            print(f"ê²½ê³ : {json_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            continue

        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            label = data["ë°œí™”ì •ë³´"]["stt"]
            city = data["ëŒ€í™”ì •ë³´"].get("cityCode", "")
            env = data["ëŒ€í™”ì •ë³´"].get("recrdEnvrn", "")
            theme = data["ëŒ€í™”ì •ë³´"].get("convrsThema", "")
            context = f"{theme.strip()}, {city.strip()}, {env.strip()} ëŒ€í™”ì…ë‹ˆë‹¤."

        file_list.append((audio_path, label, context))
        if i%10 == 0:
            print(f"{i} : {filename} ì¶”ê°€ ì™„ë£Œ")

if len(file_list) < 3:
    raise ValueError("ë°ì´í„°ì…‹ì´ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. ìµœì†Œ 3ê°œ ì´ìƒì˜ .wav/.json ìŒì´ í•„ìš”í•©ë‹ˆë‹¤.")

# Train/Valid/Test ë°ì´í„° ë¶„í• 
train_data, temp_data = train_test_split(file_list, test_size=0.3, random_state=42)
valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)

train_loader = DataLoader(ContextDataset(train_data), batch_size=1, shuffle=True)
valid_loader = DataLoader(ContextDataset(valid_data), batch_size=1, shuffle=False)

# 7. í•™ìŠµ ë£¨í”„
num_epochs = 1
model.train()
tokenizer = whisper.tokenizer.get_tokenizer(multilingual=model.is_multilingual)
losslst = []

for epoch in range(num_epochs):
    train_loss_epoch = 0
    loop = tqdm(train_loader, leave=True)
    for audio, label in loop:
        audio = audio.to(device)
        audio = whisper.pad_or_trim(audio)
        mel = whisper.log_mel_spectrogram(audio).to(device)

        tokens = tokenizer.encode(label[0])
        tokens = torch.tensor(tokens, device=device).unsqueeze(0)

        out = model(mel, tokens[:, :-1])

        loss = loss_fn(
            out.view(-1, out.size(-1)),
            tokens[:, 1:].reshape(-1)
        )

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss_epoch += loss.item()
        loop.set_description(f"Epoch {epoch+1}")
        loop.set_postfix(loss=loss.item())
        losslst.append(loss.item())
        print(loss.item(),"\n")

    # ê²€ì¦ ë£¨í”„
    model.eval()
    val_losses = []
    with torch.no_grad():
        for audio, label in valid_loader:
            audio = audio.to(device)
            audio = whisper.pad_or_trim(audio)
            mel = whisper.log_mel_spectrogram(audio).to(device)
            tokens = tokenizer.encode(label[0])
            tokens = torch.tensor(tokens, device=device).unsqueeze(0)
            out = model(mel, tokens[:, :-1])
            val_loss = loss_fn(out.view(-1, out.size(-1)), tokens[:, 1:].reshape(-1))
            val_losses.append(val_loss.item())

    val_loss_mean = sum(val_losses)/len(val_losses)
    print(f"\nâœ… Epoch {epoch+1} ì™„ë£Œ! Validation Loss: {val_loss_mean:.4f}\n")
    model.train()

# 8. ëª¨ë¸ ì €ì¥
save_path = "/content/drive/MyDrive/á„‹á…µá†«á„Œá…µá„‹á…³á†¼á„á…µá†·á„‘á…³á†¯/0522_validation.pt"
os.makedirs(os.path.dirname(save_path), exist_ok=True)
torch.save(model.state_dict(), save_path)
print(f"\nëª¨ë¸ ì €ì¥ {save_path}")

!jupyter nbconvert --to script "/content/drive/MyDrive/HeardUGIT/sswu-lc5500-aiapp/HeardU"