# -*- coding: utf-8 -*-
"""Heard_U.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SQE4to2_hyE3H5UCUhedC2MO_Su2eG2_
"""

!pip install numpy==1.24.4

from google.colab import drive
drive.mount('/content/drive')

import os
import zipfile
import json
import random
from sklearn.model_selection import train_test_split

json_zip_path = "/content/drive/MyDrive/ì¸ì§€ì‘íŒ€í”Œ/content/json_files/zip/[ë¼ë²¨]1.AIì±—ë´‡.zip"
wav_zip_path = "/content/drive/MyDrive/ì¸ì§€ì‘íŒ€í”Œ/content/wav_files/zip/[ì›ì²œ]1.AIì±—ë´‡.zip"


json_extract_dir = "/content/json_unzip"
wav_extract_dir = "/content/wav_unzip"


def unzip(zip_path, extract_to):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_to)

unzip(json_zip_path, json_extract_dir)
unzip(wav_zip_path, wav_extract_dir)


file_list = []
i = 0

for root, dirs, files in os.walk(json_extract_dir):
    for filename in files:
        if not filename.endswith(".json"):
            continue

        base_name = filename[:-5]  # ".json" ì œê±°
        json_path = os.path.join(root, filename)
        wav_path = json_path.replace(json_extract_dir, wav_extract_dir).replace(".json", ".wav")

        if not os.path.exists(wav_path):
            print(f"ê²½ê³ : {wav_path} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (continue)")
            continue

        with open(json_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
            label = data["ë°œí™”ì •ë³´"]["stt"]

        file_list.append((wav_path, label, ""))
        i += 1
        if i % 10 == 0:
            print(f"{i}ê°œ íŒŒì¼ ì¶”ê°€ ì™„ë£Œ")


if len(file_list) > 10000:
    # ì „ì²´ì—ì„œ ëœë¤í•˜ê²Œ 5000ê°œ ê³¨ë¼ì„œ ë®ì–´ì“°ê¸°
    file_list = random.sample(file_list, 10000)
    print(f"5000ê°œ ì¶”ì¶œ.")

train_data, temp_data = train_test_split(file_list, test_size=0.3, random_state=42)
valid_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)

!pip install -q openai-whisper

!apt-get update -qq && apt-get install -qq -y ffmpeg

import os
import json
import torch
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from tqdm import tqdm
import whisper

class ContextDataset(Dataset):
    def __init__(self, file_list):

        super().__init__()
        self.file_list = file_list

    def __len__(self):
        return len(self.file_list)

    def __getitem__(self, idx):
        audio_path, label, _context = self.file_list[idx]

        import torchaudio
        waveform, sr = torchaudio.load(audio_path)
        waveform = waveform.squeeze(0)
        waveform = waveform.to(torch.float32)

        return waveform, label

##ëª¨ë¸ë¡œë“œ##
#model_path = "/content/drive/MyDrive/epoch_15.pt"
device = "cuda" if torch.cuda.is_available() else "cpu"

model = whisper.load_model("base", download_root=None)
model.to(device)

tokenizer = whisper.tokenizer.get_tokenizer(multilingual=model.is_multilingual)

# Loss í•¨ìˆ˜
loss_fn = torch.nn.CrossEntropyLoss(ignore_index=-100)

# Optimizer
optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999), eps=1e-8)

import re

def clean_text(text, repeat_limit=3):
    # íƒœê·¸ ì œê±°: (NO:), (SP:), (FP:), (SN:)
    text = re.sub(r"\((NO|SP|SN|FP):[^\)]*\)", "", text)
    text = re.sub(r"\((NO|SP|SN|FP)\)", "", text)

    # íŠ¹ìˆ˜ë¬¸ì ì œê±°: (), ., ?, ! .....
    text = re.sub(r"[().?!]", "", text)

    # ë°˜ë³µë˜ëŠ” ê°íƒ„ì‚¬ ì œê±°: ã…‹ã…‹, ã…ã…
    text = re.sub(r"(ã…‹|ã…){2,}", "", text)

    # ê°™ì€ ë‹¨ì–´ ë°˜ë³µ ì œê±°: "ê·¸ê²Œ ê·¸ê²Œ ê·¸ê²Œ" â†’ "ê·¸ê²Œ"
    text = re.sub(r"\b(\w+)(\s+\1)+\b", r"\1", text)

    # ì˜ë¯¸ ì—†ëŠ” ë‹¨ì–´ ë°˜ë³µ tail ì œê±°
    tokens = text.strip().split()
    for i in range(len(tokens)):
        repeat_chunk = tokens[i:i+repeat_limit]
        if len(repeat_chunk) == repeat_limit and all(t == repeat_chunk[0] for t in repeat_chunk):
            tokens = tokens[:i]
            break
    text = " ".join(tokens)

    # ê³µë°± ì •ë¦¬
    text = re.sub(r"\s{2,}", " ", text).strip()

    return text


def collate_fn(batch):
    waveforms = [item[0] for item in batch]
    labels = [item[1] for item in batch]
    B = len(waveforms)

    # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
    processed_audios = []
    for w in waveforms:
        w_pt = whisper.pad_or_trim(w.to(device))
        processed_audios.append(w_pt)

    mel_list = []
    for w_pt in processed_audios:
        mel = whisper.log_mel_spectrogram(w_pt)
        mel_list.append(mel)
    mels = torch.stack(mel_list, dim=0).to(device)

    #í…ìŠ¤íŠ¸ ì •ì œ í›„ í† í¬ë‚˜ì´ì¦ˆ
    token_lists = []
    for lbl in labels:
        cleaned_label = clean_text(lbl)
        token_ids = tokenizer.encode(cleaned_label)
        token_ids = torch.tensor(token_ids, dtype=torch.long)
        token_lists.append(token_ids)

    max_len = max(t.shape[0] for t in token_lists)
    L = max_len - 1
    input_tokens = torch.full((B, L), tokenizer.eot, dtype=torch.long, device=device)
    target_tokens = torch.full((B, L), -100, dtype=torch.long, device=device)

    for i, t in enumerate(token_lists):
        if t.shape[0] <= 1:
            continue
        inp = t[:-1]
        tgt = t[1:]
        length = inp.shape[0]
        input_tokens[i, :length] = inp.to(device)
        target_tokens[i, :length] = tgt.to(device)

    return mels, input_tokens, target_tokens

batch_size = 16

train_loader = DataLoader(
    ContextDataset(train_data),
    batch_size=batch_size,
    shuffle=True,
    collate_fn=collate_fn,
    num_workers=1,
    pin_memory=True
)
valid_loader = DataLoader(
    ContextDataset(valid_data),
    batch_size=batch_size,
    shuffle=False,
    collate_fn=collate_fn,
    num_workers=1,
    pin_memory=True
)

import matplotlib.pyplot as plt
train_losses = []
val_losses_all = []

num_epochs = 5
model.train()
dropout = torch.nn.Dropout(p=0.1).to(device)

for epoch in range(num_epochs):
    train_loss_epoch = 0.0
    loop = tqdm(train_loader, leave=True)

    for mels, input_tokens, target_tokens in loop:

        logits = model(mels, input_tokens)
        logits = dropout(logits)

        B, L, V = logits.shape
        loss = loss_fn(
            logits.view(-1, V),
            target_tokens.view(-1)
        )

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        train_loss_epoch += loss.item()
        loop.set_description(f"Epoch {epoch+1}")
        loop.set_postfix(train_loss=loss.item())


    if len(train_loader) > 0:
        avg_train_loss = train_loss_epoch / len(train_loader)
        print(f"\nâœ… Epoch {epoch+1} í•™ìŠµ ì™„ë£Œ! í‰ê·  Train Loss: {avg_train_loss:.4f}")
        train_losses.append(avg_train_loss)
    else:
        print(f"Warning: Epoch {epoch+1}ì—ì„œ train_loaderê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        train_losses.append(None)

# ê²€ì¦ ë£¨í”„
    model.eval()
    val_losses = []

    with torch.no_grad():
        for mels, input_tokens, target_tokens in valid_loader:
            logits = model(mels, input_tokens)
            B, L, V = logits.shape
            val_loss = loss_fn(
                logits.view(-1, V),
                target_tokens.view(-1)
            )
            val_losses.append(val_loss.item())

    if len(val_losses) > 0:
        val_loss_mean = sum(val_losses) / len(val_losses)
        print(f"    âœ”ï¸ Epoch {epoch+1} ê²€ì¦ ì™„ë£Œ! Validation Loss: {val_loss_mean:.4f}\n")
        val_losses_all.append(val_loss_mean)
    else:
        print(f"âš ï¸ Warning: Epoch {epoch+1}ì—ì„œ valid_loaderê°€ ë¹„ì—ˆìŠµë‹ˆë‹¤.")
        val_losses_all.append(None)

    model.train()


plt.figure(figsize=(10, 5))
plt.plot(range(1, num_epochs+1), train_losses, label="Train Loss")
plt.plot(range(1, num_epochs+1), val_losses_all, label="Validation Loss")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training vs Validation Loss")
plt.legend()
plt.grid(True)
plt.tight_layout()
plt.show()

# 8. ëª¨ë¸ ì €ì¥
save_path = "/content/drive/MyDrive/ì¸ì§€ì‘íŒ€í”Œ/data5000_epoch15.pt"

os.makedirs(os.path.dirname(save_path), exist_ok=True)
torch.save(model.state_dict(), save_path)
print(f"\nğŸ“¦ ëª¨ë¸ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
